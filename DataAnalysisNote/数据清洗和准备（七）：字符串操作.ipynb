{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 字符串对象方法\n",
    "- `y.split(x)`：以x将y拆分，返回列表\n",
    "- `y.strip()`：去除字符串中的空白符（包括换行符），返回新字符串\n",
    "- `x.join(list)`：将list中的元素组合成一个字符串，每个元素之间使用x分隔\n",
    "- `x in y`：判断x是否在y中，返回布尔值\n",
    "- `y.index(x)`：返回x在y中第一次出现的位置，若y中不存在x，抛出`ValueError`异常\n",
    "- `y.find(x)`：返回x在y中第一次出现的位置，若y中不存在x，返回-1\n",
    "- `y.count(x)`：返回x在y中出现的次数\n",
    "- `y.replace(x,z)`：将y中的x替换为z，若z是空字符串则移除x，返回新字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['China', 'USA', ' UK']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 'China,USA, UK'\n",
    "y.split(',')  # 拆分字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['China', 'USA', 'UK']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = [x.strip() for x in y.split(',')]  # 去除空白符\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China::USA::UK'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'::'.join(countries)  # 使用指定分隔符将列表元素组合成字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'UK' in y  # 判断字符串是否在另外个字符串中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“S”出现的位置：7,“K”出现的位置：12，“U”出现次数：2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'“S”出现的位置：'+str(y.index('S'))+',“K”出现的位置：' + \\\n",
    "    str(y.find('K'))+'，“U”出现次数：'+str(y.count('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China::USA:: UK'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.replace(',', '::')  # 替换指定内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China,USA,UK'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.replace(' ', '')  # 替换内容是空字符串相当于删除要替换的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/字符串对象方法.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 正则表达式\n",
    "使用正则表达式调用字符串方法处理字符串时，一般要同时传入正则表达式和需处理的字符串，如`re.split([正则],text)`  \n",
    "- `compile([正则])`：可以自己编译一个包含了正则表达式的可重用的regex对象，下次需要使用同样正则表达式调用其他方法的时候，直接使用编译后的对象进行调用，无需再次传入正则表达式。在需要大量调用同样正则表达式的情况下，建议先编译正则表达式，以节省CPU时间。\n",
    "- `findall([正则],text)`：查找text里的所有匹配内容\n",
    "- `search([正则],text)`：在text里查找第一个匹配的字符串，并返回一个匹配对象，包含匹配字符串的起始和结束位置，可以对text使用起始和结束位置进行切片获取匹配的结果\n",
    "- `match([正则],text)`：从text起始位置开始匹配\n",
    "- `sub([正则],repl,text)`：将text里匹配到的内容替换为repl字符串，返回新字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['China', 'USA', 'UK', 'Japen']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'China   USA  \\t UK \\t  Japen'\n",
    "re.split('\\s+', text)  # 运行时先编译正则表达式，然后再调用split方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['China', 'USA', 'UK', 'Japen']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile('\\s+')  # 将正则表达式编译进regex对象中\n",
    "regex.split(text)  # 使用编译过的对象时，自动代入正则表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Dave dave@google.com\n",
    "Steve steve@gmail.com\n",
    "Rob rob@gmail.com\n",
    "Ryan ryan@yahoo.com\n",
    "\"\"\"\n",
    "pattern = r'[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}'  # 电子邮件格式的正则表达式\n",
    "\n",
    "# re.IGNORECASE忽略大小写\n",
    "regex = re.compile(pattern, flags=re.IGNORECASE)  # 编译正则表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dave@google.com', 'steve@gmail.com', 'rob@gmail.com', 'ryan@yahoo.com']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(5, 20), match='dave@google.com'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = regex.search(text)\n",
    "m  # search()找到第一个匹配内容并返回匹配对象，包含了匹配结果的起始和结束位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dave@google.com'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[m.start():m.end()]  # 切片方式获取匹配内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(regex.match(text))  # match()只从字符串起始位置开始匹配，因此匹配不到结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dave 电子邮件\n",
      "Steve 电子邮件\n",
      "Rob 电子邮件\n",
      "Ryan 电子邮件\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(regex.sub('电子邮件', text))  # sub()替换匹配到的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分段模式**  \n",
    "如果希望将正则表达式匹配的结果分段，可以在正则表达式里将需要分段的部分用圆括号包起来\n",
    "- 匹配得到的是一个匹配对象，可使用该对象的`groups()`方法返回各分段组成的元组\n",
    "- `findall()`返回一个元组列表\n",
    "- `sub()`能通过诸如\\1、\\2之类的特殊符号访问分段匹配结果中的各分段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面将邮件地址的用户名、域名和后缀所代表的正则表达式用圆括号包起来，实现分段模式\n",
    "pattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})'\n",
    "regex = re.compile(pattern, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wesm', 'bright', 'net')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = regex.match('wesm@bright.net')  # 分段匹配结果是个匹配对象\n",
    "m.groups()  # 使用groups()返回分段结果组成的元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dave', 'google', 'com'),\n",
       " ('steve', 'gmail', 'com'),\n",
       " ('rob', 'gmail', 'com'),\n",
       " ('ryan', 'yahoo', 'com')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.findall(text)  # findall()分段模式下返回元组列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dave Username: dave, Domain: google, Suffix: com\n",
      "Steve Username: steve, Domain: gmail, Suffix: com\n",
      "Rob Username: rob, Domain: gmail, Suffix: com\n",
      "Ryan Username: ryan, Domain: yahoo, Suffix: com\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sub()使用\\1,\\2访问各分段\n",
    "print(regex.sub(r'Username: \\1, Domain: \\2, Suffix: \\3', text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/正则方法.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 矢量化数据中的字符串处理\n",
    "经常会遇到需要对矢量化数据如DataFrame或Series中的字符串进行处理，比如规整化、缺失数据处理等。一般情况下，我们可以使用`data.map()`方法，传入一个字符串处理函数或者匿名函数来处理每个元素，但如果存在NaN值则会报错。这时我们可以使用Series的str属性来访问这些方法，并会跳过NaN值。对于元素内容的获取可以使用`str.get()`或`str[]`方法来获取，`str[]`还可以进行切片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     dave@google.com\n",
       "Steve    steve@gmail.com\n",
       "Rob        rob@gmail.com\n",
       "Wes                  NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Dave': 'dave@google.com', 'Steve': 'steve@gmail.com',\n",
    "        'Rob': 'rob@gmail.com', 'Wes': np.nan}\n",
    "data = pd.Series(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     False\n",
       "Steve     True\n",
       "Rob       True\n",
       "Wes        NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 要查找包含‘gmail’字符串内容\n",
    "# 如果使用data.map(lambda x:'gmail' in x)，会因为存在NaN而报错\n",
    "# 使用str.contains可以跳过NaN\n",
    "data.str.contains('gmail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     DAVE@GOOGLE.COM\n",
       "Steve    STEVE@GMAIL.COM\n",
       "Rob        ROB@GMAIL.COM\n",
       "Wes                  NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把所有内容变成大写\n",
    "# data.map(str.upper)会抛出TypeError错误\n",
    "# 使用str属性调用upper方法可以跳过NaN\n",
    "data.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     [(dave, google, com)]\n",
       "Steve    [(steve, gmail, com)]\n",
       "Rob        [(rob, gmail, com)]\n",
       "Wes                        NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正则表达式的方法同样适用\n",
    "data.str.findall(pattern, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     True\n",
       "Steve    True\n",
       "Rob      True\n",
       "Wes       NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = data.str.match(pattern, flags=re.IGNORECASE)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave       a\n",
       "Steve      t\n",
       "Rob        o\n",
       "Wes      NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用字符串的索引号获取内容\n",
    "data.str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     gle.com\n",
       "Steve    ail.com\n",
       "Rob      ail.com\n",
       "Wes          NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str[]可以切片\n",
    "data.str[-7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas字符串方法**\n",
    "![title](img/矢量化字符串操作.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
